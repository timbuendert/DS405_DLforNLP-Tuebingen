{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_4_Buendert_Tim.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "gURMVVNkhskb",
        "OrAoqk-8m2pf",
        "HlJ2R5GBE36E",
        "3lwgpEUJGUcX",
        "CmP4YNR7fV2Q",
        "1lyUqMqrfZ5V",
        "13ad67cXNVOJ",
        "Qtcv4GnFGqkd",
        "9TRaxGJKGs3y",
        "T1cEOoEKGv0d",
        "vSPqn4SeGxkm"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ead16a3f569448bbbe0f48ed6648502e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f89dcd5f04a7468782d86b6ac4b1efb3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_51ca735390d140ce9fa3f72620357e3a",
              "IPY_MODEL_50d1a8ee2d6f41539a00a1eb992c7eff",
              "IPY_MODEL_163c55e10d9543bb9bdac420562a3611"
            ]
          }
        },
        "f89dcd5f04a7468782d86b6ac4b1efb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51ca735390d140ce9fa3f72620357e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6ef6f993397a4be5961474923b90a5db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9b94abed743436caeca32f83023065b"
          }
        },
        "50d1a8ee2d6f41539a00a1eb992c7eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6fe46570e3e44e4ea7b7aa4ef7191f48",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54f8198f68314306b561051772938820"
          }
        },
        "163c55e10d9543bb9bdac420562a3611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5966509d136e47f7940c0924cfe9297f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 75.32it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69e6061e9b894840a1f50cff869b4d10"
          }
        },
        "6ef6f993397a4be5961474923b90a5db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9b94abed743436caeca32f83023065b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6fe46570e3e44e4ea7b7aa4ef7191f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54f8198f68314306b561051772938820": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5966509d136e47f7940c0924cfe9297f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69e6061e9b894840a1f50cff869b4d10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "174bb7242d0a462e94cc8ac3e649b6cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bc5d5f3ad756422c94363795df3d8c1c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_71609c2115564e65852825cbcd6bdcfa",
              "IPY_MODEL_b87a0c39991a48279aa46486040ca6ec",
              "IPY_MODEL_e41cf62971064434a24690b32a780edf"
            ]
          }
        },
        "bc5d5f3ad756422c94363795df3d8c1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71609c2115564e65852825cbcd6bdcfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8c20cf2e9846451b9a7bb1f32d252909",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Epoch: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f21e573c07d41768348500c1b5b90f4"
          }
        },
        "b87a0c39991a48279aa46486040ca6ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fe7b1884d3fb474aa41763eb5865a49e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3006db562a9d435ba01c9fe9e3cec473"
          }
        },
        "e41cf62971064434a24690b32a780edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a5eb23db605145fba191a8bce49b7c1e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [12:10&lt;00:00, 730.70s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1eec3be7dab472f94786a7077592d3d"
          }
        },
        "8c20cf2e9846451b9a7bb1f32d252909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f21e573c07d41768348500c1b5b90f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe7b1884d3fb474aa41763eb5865a49e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3006db562a9d435ba01c9fe9e3cec473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5eb23db605145fba191a8bce49b7c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1eec3be7dab472f94786a7077592d3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eaedf3ef86064c5ea7dc5a71da862c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4ed83829f4504a0ea136a36893620ca8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_22afcc6845a347dfa528b5400d85c342",
              "IPY_MODEL_0f83401be79a489c8c573f3c94e5a2e1",
              "IPY_MODEL_b69fd768c84442aba46a1a497440ee4f"
            ]
          }
        },
        "4ed83829f4504a0ea136a36893620ca8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22afcc6845a347dfa528b5400d85c342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3cdc90332b094e82a46f2e3ec6b07314",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Iteration: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_010c89c0b8d24331962036a649dd45f8"
          }
        },
        "0f83401be79a489c8c573f3c94e5a2e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_60147a6f88524989a074eab777810810",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 581,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 581,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5684ecad78144cca0d2210eda7f82c5"
          }
        },
        "b69fd768c84442aba46a1a497440ee4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ca74e4a1e62545f98873fdd0b2e31942",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 581/581 [09:12&lt;00:00,  8.83s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3af99dc2952b4d59a8525ff0ccb0fd71"
          }
        },
        "3cdc90332b094e82a46f2e3ec6b07314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "010c89c0b8d24331962036a649dd45f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60147a6f88524989a074eab777810810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5684ecad78144cca0d2210eda7f82c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca74e4a1e62545f98873fdd0b2e31942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3af99dc2952b4d59a8525ff0ccb0fd71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRBuEx1wJGei"
      },
      "source": [
        "# Assignment 4: Practical Deep Learning for Language Processing (DS405B)\n",
        "submitted by Tim-Moritz Bündert (ID: 5635975) on February 12, 2022"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "gURMVVNkhskb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kxQx34G5iy_",
        "outputId": "9dbf2d76-19b0-461e-ed3d-cafa7f128cf1"
      },
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF9fd-2ELCYY"
      },
      "source": [
        "# set data directory\n",
        "data_dir = \"/content/drive/MyDrive/University/DS405B_PDL_for_LP/Assignment_4/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "vfAe1ULCq9_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9e1b2d0-7581-49d1-9267-21529d866f93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.96)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.16.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.11.1+cu111)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.47)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.11.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.18.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.1.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.10.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.11)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import packages\n",
        "import numpy as np\n",
        "import random\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, InputExample\n",
        "from sentence_transformers.util import cos_sim\n",
        "from sentence_transformers.cross_encoder import CrossEncoder\n",
        "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator, CERerankingEvaluator\n",
        "from sentence_transformers.datasets import NoDuplicatesDataLoader\n",
        "\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline, AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "j-0qL5MZu82t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "0fMtS20eGgPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "id": "OrAoqk-8m2pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subjqa = load_dataset('subjqa', name = 'electronics', data_dir = data_dir)\n",
        "subjqa"
      ],
      "metadata": {
        "id": "gKKKJJL-BYEh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "ead16a3f569448bbbe0f48ed6648502e",
            "f89dcd5f04a7468782d86b6ac4b1efb3",
            "51ca735390d140ce9fa3f72620357e3a",
            "50d1a8ee2d6f41539a00a1eb992c7eff",
            "163c55e10d9543bb9bdac420562a3611",
            "6ef6f993397a4be5961474923b90a5db",
            "f9b94abed743436caeca32f83023065b",
            "6fe46570e3e44e4ea7b7aa4ef7191f48",
            "54f8198f68314306b561051772938820",
            "5966509d136e47f7940c0924cfe9297f",
            "69e6061e9b894840a1f50cff869b4d10"
          ],
          "height": 347
        },
        "outputId": "89599cc6-de0a-437f-c5e2-1c4198ab2b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration electronics-70b9d0b6f00a5974\n",
            "Reusing dataset subjqa (/root/.cache/huggingface/datasets/subjqa/electronics-70b9d0b6f00a5974/1.1.0/e5588f9298ff2d70686a00cc377e4bdccf4e32287459e3c6baf2dc5ab57fe7fd)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ead16a3f569448bbbe0f48ed6648502e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['domain', 'nn_mod', 'nn_asp', 'query_mod', 'query_asp', 'q_reviews_id', 'question_subj_level', 'ques_subj_score', 'is_ques_subjective', 'review_id', 'id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 1295\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['domain', 'nn_mod', 'nn_asp', 'query_mod', 'query_asp', 'q_reviews_id', 'question_subj_level', 'ques_subj_score', 'is_ques_subjective', 'review_id', 'id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 358\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['domain', 'nn_mod', 'nn_asp', 'query_mod', 'query_asp', 'q_reviews_id', 'question_subj_level', 'ques_subj_score', 'is_ques_subjective', 'review_id', 'id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 255\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define dataset partitions\n",
        "\n",
        "subjqa_train = subjqa['train']\n",
        "subjqa_val = subjqa['validation']\n",
        "subjqa_test = subjqa['test']"
      ],
      "metadata": {
        "id": "D9VUQ57-wK7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subjqa_train[1] # print example of training partition to understand its structure "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sTjojzNFljq",
        "outputId": "d1e71785-2d35-4456-c1c8-b3f1ec823d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answers': {'ans_subj_score': [0.5083333253860474, 0.5083333253860474],\n",
              "  'answer_start': [1302, 1302],\n",
              "  'answer_subj_level': [1, 1],\n",
              "  'is_ans_subjective': [True, True],\n",
              "  'text': ['Bass is weak as expected',\n",
              "   'Bass is weak as expected, even with EQ adjusted up']},\n",
              " 'context': 'To anyone who hasn\\'t tried all the various types of headphones, it is important to remember exactly what these are: cheap portable on-ear headphones. They give a totally different sound then in-ears or closed design phones, but for what they are I would say they\\'re good. I currently own six pairs of phones, from stock apple earbuds to Sennheiser HD 518s. Gave my Portapros a run on both my computer\\'s sound card and mp3 player, using 256 kbps mp3s or better. The clarity is good and they\\'re very lightweight. The folding design is simple but effective. The look is certainly retro and unique, although I didn\\'t find it as comfortable as many have claimed. Earpads are *very* thin and made my ears sore after 30 minutes of listening, although this can be remedied to a point by adjusting the \"comfort zone\" feature (tightening the temple pads while loosening the ear pads). The cord seems to be an average thickness, but I wouldn\\'t get too rough with these. The steel headband adjusts smoothly and easily, just watch out that the slider doesn\\'t catch your hair. Despite the sore ears, the phones are very lightweight overall.Back to the sound: as you would expect, it\\'s good for a portable phone, but hardly earth shattering. At flat EQ the clarity is good, although the highs can sometimes be harsh. Bass is weak as expected, even with EQ adjusted up. To be fair, a portable on-ear would have a tough time comparing to the bass of an in-ear with a good seal or a pair with larger drivers. No sound isolation offered if you\\'re into that sort of thing. Cool 80s phones, though I\\'ve certainly owned better portable on-ears (Sony makes excellent phones in this category). Soundstage is very narrow and lacks body. A good value if you can get them for under thirty, otherwise I\\'d rather invest in a nicer pair of phones. If we\\'re talking about value, they\\'re a good buy compared to new stock apple buds. If you\\'re trying to compare the sound quality of this product to serious headphones, there\\'s really no comparison at all.Update: After 100 hours of burn-in time the sound has not been affected in any appreciable way. Highs are still harsh, and bass is still underwhelming. I sometimes use these as a convenience but they have been largely replaced in my collection.',\n",
              " 'domain': 'electronics',\n",
              " 'id': 'd476830bf9282e2b9033e2bb44bbb995',\n",
              " 'is_ques_subjective': False,\n",
              " 'nn_asp': 'high',\n",
              " 'nn_mod': 'harsh',\n",
              " 'q_reviews_id': '7c46670208f7bf5497480fbdbb44561a',\n",
              " 'query_asp': 'bass',\n",
              " 'query_mod': 'not strong',\n",
              " 'ques_subj_score': 0.5,\n",
              " 'question': 'Is this music song have a goo bass?',\n",
              " 'question_subj_level': 1,\n",
              " 'review_id': 'ce76793f036494eabe07b33a9a67288a',\n",
              " 'title': 'B00001P4ZH'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1"
      ],
      "metadata": {
        "id": "HlJ2R5GBE36E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bi_encoder_model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1', cache_folder = data_dir) # load the bi-encoder"
      ],
      "metadata": {
        "id": "GM81IVvUEhfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create training index of context-embedding pairs \n",
        "\n",
        "index_train = []\n",
        "for example in tqdm(subjqa_train):\n",
        "  context = example['context']\n",
        "  context_emb = bi_encoder_model.encode(context)\n",
        "  index_train.append({'context': context,\n",
        "                      'embedding': context_emb})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnxoytbBFdrU",
        "outputId": "f293f879-053a-4b77-868f-1fd7b0938a49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1295/1295 [00:18<00:00, 71.79it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create validation index of context-embedding pairs\n",
        "\n",
        "index_val = []\n",
        "for example in tqdm(subjqa_val):\n",
        "  context = example['context']\n",
        "  context_emb = bi_encoder_model.encode(context)\n",
        "  index_val.append({'context': context,\n",
        "                    'embedding': context_emb})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTn6YvJH3WO0",
        "outputId": "c2f26ff7-a65b-4b24-c3fc-94f0ca75bfba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 255/255 [00:02<00:00, 108.29it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create test index of context-embedding pairs\n",
        "\n",
        "index_test = []\n",
        "for example in tqdm(subjqa_test):\n",
        "  context = example['context']\n",
        "  context_emb = bi_encoder_model.encode(context)\n",
        "  index_test.append({'context': context,\n",
        "                     'embedding': context_emb})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9zDBtHHL1XA",
        "outputId": "3a756766-7635-4401-f328-daa612785d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 358/358 [00:03<00:00, 105.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2"
      ],
      "metadata": {
        "id": "3lwgpEUJGUcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two options for fine-tuning the cross-encoder `cross-encoder/ms-marco-MiniLM-L-6- v2` are possible:\n",
        "\n",
        "1) Using the `Transformers` framework with the `AutoModelForSequenceClassification` class and the \"typical\" PyTorch way to train a model\n",
        "\n",
        "2) Using the dedicated `CrossEncoder` class of `SentenceTransformers` with the built-in **.fit()** function.\n",
        "\n",
        "In the folllowing, both options will be considered and subsequently evaluated in exercise 3 and 4 where it will be then decided with which of the two versions to move on with."
      ],
      "metadata": {
        "id": "6baT05zVTZ2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, the training dataset has to be created. Apart from the original (\"gold\") training dataset (if query contains an answer: label = 1, if query is unanswerable: label = 0), additional artificial negative examples are constructed by pairing eac query with all other contexts and accordingly assigning a label of 0. Thereby, the MNR loss can be simulated and the training dataset size increased."
      ],
      "metadata": {
        "id": "hwLoFHkRTmxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset_true = []\n",
        "training_dataset_augmented = []\n",
        "for i, example_query in tqdm(enumerate(subjqa_train)):\n",
        "  query = example_query['question']\n",
        "  for j, example_context in enumerate(index_train):\n",
        "    context = example_context['context']\n",
        "    if i == j:\n",
        "      if len(example_query['answers']['text']) > 0:\n",
        "        sim = 1.0 # if there is at least one answer in this context: positive example\n",
        "      else:\n",
        "        sim = 0.0 # if no answer is present (unanswerable question): negative example\n",
        "      training_dataset_true.append({'question': query, 'context': context, 'label': sim}) # collect samples that are required to be present in training dataset\n",
        "    else:\n",
        "      sim = 0.0\n",
        "      training_dataset_augmented.append({'question': query, 'context': context, 'label': sim}) # collect artificially created samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zvChKSQBORs",
        "outputId": "c258178d-116a-447f-f550-3f82ced9415f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1295it [00:01, 780.74it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With 1295 \\* 1294 = 1,675,730 additional negative examples in **training_dataset_augmented**, training on this dataset would be computationally infeasible. Instead, it will be randomly sampled from this collection whereas the number of samples presents a hyperparameter which can be tuned using the validation dataset."
      ],
      "metadata": {
        "id": "54ZM6t5od0RG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) `Transformers`"
      ],
      "metadata": {
        "id": "CmP4YNR7fV2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# implement validation set with the same conventions\n",
        "\n",
        "validation = []\n",
        "for example in subjqa_val:\n",
        "  if len(example['answers']['text']) > 0:\n",
        "    label = 1.0\n",
        "  else:\n",
        "    label = 0.0\n",
        "  validation.append({'question': example['question'], 'context': example['context'], 'label': label})"
      ],
      "metadata": {
        "id": "OWbzouu8Q4Nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch_ce(batch):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  labels = []\n",
        "  \n",
        "  for example in batch:\n",
        "    # tokenize question and context\n",
        "    tokenized = cross_encoder_tokenizer(example['question'],\n",
        "                                        example['context'], \n",
        "                                        max_length = 512, \n",
        "                                        truncation = True, \n",
        "                                        return_tensors = \"pt\", \n",
        "                                        pad_to_max_length = True)\n",
        "\n",
        "    input_ids.append(tokenized['input_ids'])\n",
        "    attention_masks.append(tokenized['attention_mask'])\n",
        "    labels.append(example['label'])\n",
        "\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  labels = torch.tensor(labels)\n",
        "\n",
        "  return input_ids, attention_masks, labels\n",
        "\n",
        "val_dataloader_ce = DataLoader(validation, batch_size = 32, shuffle = True, collate_fn = collate_batch_ce)"
      ],
      "metadata": {
        "id": "ftcxTvGnV5Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# range for hyperparameter tuning (grid-search)\n",
        "lr_range = [1e-02, 1e-03]\n",
        "n_neg_samples = [6000, 8000, 10000]\n",
        "\n",
        "best_val_loss_overall = 100\n",
        "\n",
        "for lr in lr_range:\n",
        "  for neg_samples in n_neg_samples:\n",
        "\n",
        "    print(f'Selected Learning_rate = {lr}        Number of additional negative samples = {neg_samples}\\n')\n",
        "\n",
        "    # load model and tokenizer\n",
        "    cross_encoder_model = AutoModelForSequenceClassification.from_pretrained('cross-encoder/ms-marco-MiniLM-L-6-v2', cache_dir = data_dir)\n",
        "    cross_encoder_tokenizer = AutoTokenizer.from_pretrained('cross-encoder/ms-marco-MiniLM-L-6-v2' , cache_dir = data_dir)\n",
        "\n",
        "    # construct training dataset\n",
        "    random.seed(42)\n",
        "    augmented_training_reduced = random.sample(training_dataset_augmented, neg_samples)\n",
        "    training_dataset_t = training_dataset_true + augmented_training_reduced\n",
        "    train_dataloader_ce = DataLoader(training_dataset_t, batch_size = 128, shuffle = True, collate_fn = collate_batch_ce)\n",
        "\n",
        "    # only re-train the linear pooler and classifier\n",
        "    for param in cross_encoder_model.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    for param in cross_encoder_model.bert.pooler.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    for param in cross_encoder_model.classifier.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    cross_encoder_model = cross_encoder_model.to(device)\n",
        "    optimizer = torch.optim.Adam(cross_encoder_model.parameters(), lr=lr)\n",
        "\n",
        "    num_epochs = 8\n",
        "    best_val_loss = 100 # set so high such that learning does not break after first epoch\n",
        "\n",
        "    for epoch in range(num_epochs): \n",
        "      running_loss_train = []\n",
        "      cross_encoder_model.train()\n",
        "      for batch_train in tqdm(train_dataloader_ce):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = cross_encoder_model(input_ids = batch_train[0].to(device),\n",
        "                                      attention_mask = batch_train[1].to(device),\n",
        "                                      labels = batch_train[2].to(device))\n",
        "        \n",
        "        outputs.loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        running_loss_train.append(outputs.loss.item())\n",
        "\n",
        "      # evaluate the fine-tuned model\n",
        "      cross_encoder_model.eval()\n",
        "      running_loss_val = []\n",
        "      with torch.no_grad():\n",
        "        for batch_val in val_dataloader_ce:\n",
        "          outputs = cross_encoder_model(input_ids = batch_val[0].to(device),\n",
        "                                        attention_mask = batch_val[1].to(device),\n",
        "                                        labels = batch_val[2].to(device))\n",
        "          \n",
        "          running_loss_val.append(outputs.loss.item())\n",
        "\n",
        "      val_loss = np.mean(running_loss_val)\n",
        "      \n",
        "      print(f'Epoch {epoch + 1}:\\nTraining Loss = {np.mean(running_loss_train)}   Validation Loss = {val_loss}\\n')\n",
        "\n",
        "      if val_loss < best_val_loss:\n",
        "        cross_encoder_model_t_best = cross_encoder_model # best model over all epochs\n",
        "        best_val_loss = val_loss\n",
        "\n",
        "      else:\n",
        "        break # early stopping\n",
        "\n",
        "    if best_val_loss < best_val_loss_overall:\n",
        "      best_val_loss_overall = best_val_loss\n",
        "      cross_encoder_model_t = cross_encoder_model_t_best # best model over all hyperparameters\n",
        "      best_training_dataset_t = training_dataset_t # capture \"best\" training dataset for subsequent use\n",
        "      print('Tuned cross encoder model updated.')\n",
        "\n",
        "    print('------------------------------------\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxnctCzgVFLE",
        "outputId": "15777dd1-dd5d-4c08-c96e-e41201c3c86e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Learning_rate = 0.01        Number of additional negative samples = 6000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/57 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 57/57 [01:06<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "Training Loss = 2.5169146952399037   Validation Loss = 0.41372131928801537\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57/57 [01:06<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2:\n",
            "Training Loss = 0.072575297762166   Validation Loss = 0.3542720712721348\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57/57 [01:06<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3:\n",
            "Training Loss = 0.06744041306930676   Validation Loss = 0.3775008525699377\n",
            "\n",
            "Tuned cross encoder model updated.\n",
            "------------------------------------\n",
            "\n",
            "Selected Learning_rate = 0.01        Number of additional negative samples = 8000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [01:25<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "Training Loss = 1.8994470891887194   Validation Loss = 0.3212188482284546\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [01:25<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2:\n",
            "Training Loss = 0.05476142828391023   Validation Loss = 0.3242396414279938\n",
            "\n",
            "Tuned cross encoder model updated.\n",
            "------------------------------------\n",
            "\n",
            "Selected Learning_rate = 0.01        Number of additional negative samples = 10000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 89/89 [01:43<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "Training Loss = 1.638687427767835   Validation Loss = 0.3477076254785061\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 89/89 [01:43<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2:\n",
            "Training Loss = 0.04492150418711512   Validation Loss = 0.34807523526251316\n",
            "\n",
            "------------------------------------\n",
            "\n",
            "Selected Learning_rate = 0.001        Number of additional negative samples = 6000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57/57 [01:07<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "Training Loss = 5.1495180106476734   Validation Loss = 0.46664974093437195\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57/57 [01:07<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2:\n",
            "Training Loss = 0.13222213442388334   Validation Loss = 0.3212033826857805\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57/57 [01:06<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3:\n",
            "Training Loss = 0.09565266437436405   Validation Loss = 0.31710853427648544\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57/57 [01:07<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4:\n",
            "Training Loss = 0.08065850300747052   Validation Loss = 0.32728779688477516\n",
            "\n",
            "Tuned cross encoder model updated.\n",
            "------------------------------------\n",
            "\n",
            "Selected Learning_rate = 0.001        Number of additional negative samples = 8000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [01:25<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "Training Loss = 3.9621208638769305   Validation Loss = 0.30178481340408325\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [01:25<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2:\n",
            "Training Loss = 0.10040336260444498   Validation Loss = 0.3317076005041599\n",
            "\n",
            "Tuned cross encoder model updated.\n",
            "------------------------------------\n",
            "\n",
            "Selected Learning_rate = 0.001        Number of additional negative samples = 10000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 89/89 [01:43<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "Training Loss = 3.3618229365583217   Validation Loss = 0.34776404686272144\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 89/89 [01:43<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2:\n",
            "Training Loss = 0.07899586843808046   Validation Loss = 0.3408302888274193\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 89/89 [01:43<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3:\n",
            "Training Loss = 0.059072932479589176   Validation Loss = 0.3470219187438488\n",
            "\n",
            "------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hence, the best result was achieved using a learning rate of 0.001 and 8,000 additional negative samples after one epoch. Therefore, these values will be stored."
      ],
      "metadata": {
        "id": "0Y9_ncVaDnhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_ce_tuned = 1\n",
        "lr_ce_tuned = 0.001"
      ],
      "metadata": {
        "id": "705JLwV1cj8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) `SentenceTransformers`"
      ],
      "metadata": {
        "id": "1lyUqMqrfZ5V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using `SententenceTransformers`, the **CERerankingEvaluator** can be used to evaluate the fine-tuned model for the specific application of re-ranking. To set this Evaluator up, each answerable query along with its positive context will be paired with all other contexts which serve as the negative ones.\n",
        "\n",
        "Also, the best training dataset from the `Transformers` approach is used (and converted) for this approach as well such that the two methods are comparable."
      ],
      "metadata": {
        "id": "YilBQApafqol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_samples = []\n",
        "all_val_contexts = [example['context'] for example in subjqa_val]\n",
        "for example in subjqa_val:\n",
        "  if len(example['answers']['text']) > 0:\n",
        "    query = example['question']\n",
        "    pos_context = example['context']\n",
        "    neg_contexts = copy.deepcopy(all_val_contexts)\n",
        "    neg_contexts.remove(pos_context)\n",
        "    eval_samples.append({'query': query, 'positive': [pos_context], 'negative': neg_contexts})\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "evaluator = CERerankingEvaluator(eval_samples)\n",
        "\n",
        "training_dataset_st = [InputExample(texts = [example['question'], example['context']], label = int(example['label'])) for example in best_training_dataset_t]\n",
        "training_dataloader_st = DataLoader(training_dataset_st, batch_size = 16) # smaller batch size due to memory constraints"
      ],
      "metadata": {
        "id": "DtH7GYddsbMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since it is more difficult to evaluate the best hyperparameters for the `SentenceTransformers` approach (ideas can be seen under the sub-section **Additional considerations**), the hyperparameters from the `Transformers` approach are used (acknowledging that this biases the comparison to some extent).\n",
        "\n",
        "Also, overfitting is not an issue here because the evaluator automatically selects the best trained model."
      ],
      "metadata": {
        "id": "kYVf8ipMp9oP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cross_encoder_model_st = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', num_labels = 1)\n",
        "cross_encoder_model_st.fit(train_dataloader = training_dataloader_st,\n",
        "                           evaluator = evaluator,\n",
        "                           epochs = epochs_ce_tuned,\n",
        "                           evaluation_steps = int(len(training_dataloader_st) / 2), # evaluate after half of an epoch\n",
        "                           optimizer_class = torch.optim.Adam,\n",
        "                           optimizer_params = {'lr': lr_ce_tuned}, # use fine-tuned learning rate from Transformers method\n",
        "                           warmup_steps = int(len(training_dataloader_st)*0.1),\n",
        "                           show_progress_bar = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "174bb7242d0a462e94cc8ac3e649b6cc",
            "bc5d5f3ad756422c94363795df3d8c1c",
            "71609c2115564e65852825cbcd6bdcfa",
            "b87a0c39991a48279aa46486040ca6ec",
            "e41cf62971064434a24690b32a780edf",
            "8c20cf2e9846451b9a7bb1f32d252909",
            "5f21e573c07d41768348500c1b5b90f4",
            "fe7b1884d3fb474aa41763eb5865a49e",
            "3006db562a9d435ba01c9fe9e3cec473",
            "a5eb23db605145fba191a8bce49b7c1e",
            "a1eec3be7dab472f94786a7077592d3d",
            "eaedf3ef86064c5ea7dc5a71da862c6a",
            "4ed83829f4504a0ea136a36893620ca8",
            "22afcc6845a347dfa528b5400d85c342",
            "0f83401be79a489c8c573f3c94e5a2e1",
            "b69fd768c84442aba46a1a497440ee4f",
            "3cdc90332b094e82a46f2e3ec6b07314",
            "010c89c0b8d24331962036a649dd45f8",
            "60147a6f88524989a074eab777810810",
            "d5684ecad78144cca0d2210eda7f82c5",
            "ca74e4a1e62545f98873fdd0b2e31942",
            "3af99dc2952b4d59a8525ff0ccb0fd71"
          ]
        },
        "id": "bgNsJsoythQH",
        "outputId": "b1883fe6-1bea-4c36-88e6-b195a817f029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "174bb7242d0a462e94cc8ac3e649b6cc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eaedf3ef86064c5ea7dc5a71da862c6a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Iteration:   0%|          | 0/581 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional considerations"
      ],
      "metadata": {
        "id": "13ad67cXNVOJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this subsection, some further ideas/ experiments that took place in connection to the fine-tuning of the cross-encoder are presented."
      ],
      "metadata": {
        "id": "SqkjontWiQuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, several ideas with regard to the fine-tuning of the `SentenceTransformers` method were evaluated. Below, both an approach to use the **BCEWithLogitsLoss** and using the re-ranking error are displayed.\n",
        "\n",
        "Both methods were also employed with the model, but did not yield comparably good results and therefore, these approaches were not considered for the final version."
      ],
      "metadata": {
        "id": "XwBWeOLHmshC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) BCEWithLogitsLoss()\n",
        "outputs = torch.tensor(cross_encoder_model.predict([[subjqa_val[i]['question'], subjqa_val[i]['context']] for i in range(len(subjqa_val))]))\n",
        "# set up 'targets' as corresponding 0-1 vector with regard to whether answer is present in example or not\n",
        "loss = torch.nn.BCEWithLogitsLoss()\n",
        "loss_epoch = loss(outputs, targets)\n",
        "\n",
        "# 2) Re-ranked index as loss\n",
        "loss = 0\n",
        "for n, example in enumerate(subjqa_val):\n",
        "  scores = cross_encoder_model.predict([[example['question'], subjqa_val[i]['context']] for i in range(len(subjqa_val))])\n",
        "  ranking_index = np.array(scores).argsort()[::-1]\n",
        "  result = list(ranking_index).index(n) # loss of training example is its position after re-ranking\n",
        "  loss += result"
      ],
      "metadata": {
        "id": "lyUIfpzrhKqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition, several different ideas to construct the training dataset were tried out. \n",
        "\n",
        "The first method does not select random artifical negative samples, but rather takes the ten contexts for each query, which yielded the highest cosine similarity. Thereby, the intention was to feed the model those prime negative examples which are supposed to be extremely hard and may be helpful for the model.\n",
        "\n",
        "Second, it was also evaluated to not assign hard labels to the positive and negative examples, but rather use the cosine similarity of the bi-encoder embeddings.\n",
        "\n",
        "Eventually, both approaches did not result in any performance gains, but rather yielded worse results and were therefore not considered any further."
      ],
      "metadata": {
        "id": "KC0UMX06neIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Prime negative examples\n",
        "training_dataset_augmented = []\n",
        "\n",
        "for sample in tqdm(subjqa_train):\n",
        "  if len(sample['answers']['text']) > 0:\n",
        "    query = sample['question']\n",
        "    context = sample['context']\n",
        "\n",
        "    # use bi-encoder to retrieve top 10 contexts with highest cosine similaritity\n",
        "    query_emb = bi_encoder_model.encode(query)\n",
        "    cos_similarities = [cos_sim(query_emb, context['embedding']) for context in index_train]\n",
        "    \n",
        "    rel_contexts = np.array(cos_similarities).argsort()[-10:][::-1]\n",
        "    contexts = [index_train[rel_context]['context'] for rel_context in rel_contexts]\n",
        "    if context in contexts:\n",
        "      contexts.remove(context)\n",
        "\n",
        "    for c in contexts:\n",
        "        training_dataset_augmented.append(InputExample(texts = [query, c], label = 0))\n",
        "\n",
        "# 2) Cosine similarity as soft label\n",
        "sim = (cos_sim(query_emb, example_context['embedding']) + 1) / 2 # normalize cosine similarity to (0,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjZ6uMwp2aBl",
        "outputId": "4cfe2b73-4068-4f40-861e-708f31d9e73c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1295/1295 [03:07<00:00,  6.92it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3\n"
      ],
      "metadata": {
        "id": "Qtcv4GnFGqkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_results_t = []\n",
        "test_results_st = []\n",
        "\n",
        "for sample in tqdm(subjqa_test):\n",
        "  query = sample['question']\n",
        "\n",
        "  # use bi-encoder to retrieve top n (30) contexts with highest cosine similaritity (as experiments showed that n = 30 performs better than n = 10)\n",
        "  query_emb = bi_encoder_model.encode(query)\n",
        "  cos_similarities = [cos_sim(query_emb, context['embedding']) for context in index_test]\n",
        "  rel_contexts = np.array(cos_similarities).argsort()[-30:][::-1]\n",
        "\n",
        "\n",
        "  # use fine-tuned cross-encoders to re-rank those relevant contexts\n",
        "  ## 1) Transformers approach\n",
        "  scores_t = []\n",
        "  cross_encoder_model_t.eval()\n",
        "  with torch.no_grad():\n",
        "    for context_id in rel_contexts:\n",
        "      tokenized = cross_encoder_tokenizer(query, \n",
        "                                          index_test[context_id]['context'], \n",
        "                                          truncation = 'only_second',\n",
        "                                          max_length = 512, \n",
        "                                          return_tensors = \"pt\", \n",
        "                                          pad_to_max_length = True).to(device)\n",
        "\n",
        "      scores_t.append(cross_encoder_model_t(**tokenized).logits)\n",
        "  ranked_contexts_t = np.array(scores_t).argsort()[::-1] # re-rank contexts\n",
        "  result_t = [{'context': index_test[rel_contexts[rank]]['context'], 'score': scores_t[rank]} for rank in ranked_contexts_t]\n",
        "  test_results_t.append(result_t)\n",
        "\n",
        "\n",
        "  ## 2) SentenceTransformers approach\n",
        "  scores_st = [cross_encoder_model_st.predict([(query, index_test[rel_context]['context'])])[0] for rel_context in rel_contexts]\n",
        "  ranked_contexts_st = np.array(scores_st).argsort()[::-1] # re-rank contexts\n",
        "  result_st = [{'context': index_test[rel_contexts[rank]]['context'], 'score': scores_st[rank]} for rank in ranked_contexts_st]\n",
        "  test_results_st.append(result_st)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_TV0zNXxROl",
        "outputId": "1d964961-310c-4e0e-f9ef-8c99796866c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/358 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 358/358 [03:26<00:00,  1.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4"
      ],
      "metadata": {
        "id": "9TRaxGJKGs3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recall_test_samples(test_results, k = 10):\n",
        "  counter = 0\n",
        "  num_tests = 0\n",
        "  for i, sample in enumerate(subjqa_test):\n",
        "    if len(sample['answers']['text']) > 0: # remove unanswerable examples from evaluation\n",
        "      num_tests += 1\n",
        "      answer = sample['context'] # select correct context\n",
        "      results = test_results[i]\n",
        "      rel_contexts = [results[j]['context'] for j in range(k)] \n",
        "      if answer in rel_contexts: # evaluate whether correct context is among the k best reranked ones\n",
        "        counter += 1\n",
        "\n",
        "  return counter / num_tests"
      ],
      "metadata": {
        "id": "zgATyxVp4Yz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_range = np.arange(len(test_results_t[0])) + 1 # evaluate for each possible k within n (gives a more detailed view than only k = 1,3,5,10)\n",
        "\n",
        "recalls_test_t = [recall_test_samples(test_results_t, k) for k in k_range] # evaluate for Transformers approach\n",
        "recalls_test_st = [recall_test_samples(test_results_st, k) for k in k_range] # evaluate for SentenceTransformers approach"
      ],
      "metadata": {
        "id": "vF56K_7p6Fam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 8))\n",
        "plt.plot(k_range, recalls_test_t, label = 'Recall of the tuned Transformers method')\n",
        "plt.plot(k_range, recalls_test_st, label = 'Recall of the tuned Sentence Transformers method') \n",
        "plt.xlabel(\"k\")\n",
        "plt.ylabel(\"Recall\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "LUq75JkEvBW9",
        "outputId": "9ef51720-f71c-4da5-85e7-4f9ca0824ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyzing the graph, it can be seen that the `Transformers` approach consistently outperforms the `SentenceTransformer` one. However, this was somehow expected due to the introduced bias when selecting the hyperparameters. \n",
        "\n",
        "Since we trained the cross-encoder to potentially reduce k while maintaining a high recall, **k = 20** is selected because there, recall performance begins to saturate. While this increase in k compared to k = 10 will result in a slower final reader step, it is reasonable given the recall performance to ensure that the correct context is present among the selected ones.\n",
        "\n",
        "Also, as **n = 30** worked reasonably well, this parameter is also set."
      ],
      "metadata": {
        "id": "EIJBSQw_YrOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_best = 20\n",
        "n_best = 30"
      ],
      "metadata": {
        "id": "t5uES2tU2lOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 5"
      ],
      "metadata": {
        "id": "T1cEOoEKGv0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch_reader(batch):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  token_type_ids = []\n",
        "  start_pos = []\n",
        "  end_pos = []\n",
        "\n",
        "  for example in batch:\n",
        "\n",
        "    tokenized = reader_tokenizer(example['question'], \n",
        "                                 example['context'], \n",
        "                                 return_overflowing_tokens = True, \n",
        "                                 max_length = 512, \n",
        "                                 stride = stride_selected, \n",
        "                                 return_tensors = \"pt\", \n",
        "                                 pad_to_max_length = True, \n",
        "                                 return_offsets_mapping = True,  # return (char_start, char_end) for each token\n",
        "                                 truncation = False)\n",
        "    \n",
        "    for i, offset in enumerate(tokenized[\"offset_mapping\"]): # go through different parts (windows) of example produced by stride\n",
        "      sequence_ids = tokenized.sequence_ids(i)\n",
        "\n",
        "      # find context of this window\n",
        "      idx = 0\n",
        "      while sequence_ids[idx] != 1:\n",
        "          idx += 1\n",
        "      context_start = idx\n",
        "      while sequence_ids[idx] == 1:\n",
        "          idx += 1\n",
        "      context_end = idx - 1 # last index was the last one of this window\n",
        "\n",
        "      # if example contains no answer: label with CLS token\n",
        "      if len(example['answers']['answer_start']) == 0:\n",
        "        input_ids.append(tokenized['input_ids'][i].unsqueeze(0))\n",
        "        attention_masks.append(tokenized['attention_mask'][i].unsqueeze(0))\n",
        "        token_type_ids.append(tokenized['token_type_ids'][i].unsqueeze(0))\n",
        "        start_pos.append(0)\n",
        "        end_pos.append(0)\n",
        "\n",
        "      else:\n",
        "        found_start = []\n",
        "        found_end = []\n",
        "        for answer_nr in range(len(example['answers']['answer_start'])): # iterate through all answers of example\n",
        "          start_char = example['answers']['answer_start'][answer_nr]\n",
        "          end_char = example['answers']['answer_start'][answer_nr] + len(example['answers']['text'][answer_nr])\n",
        "\n",
        "          if offset[context_start][0] > end_char or offset[context_end][1] < start_char: # check whether answer is not fully in span of context (on character-level)\n",
        "            continue\n",
        "            \n",
        "          else:\n",
        "            # find start and end token positions (mapping from their character positions to indices)\n",
        "            start_idx = context_start\n",
        "            while start_idx <= context_end and offset[start_idx][0] <= start_char:\n",
        "                start_idx += 1\n",
        "            found_start.append(start_idx - 1) # remove the last step\n",
        "\n",
        "            end_idx = context_end\n",
        "            while end_idx >= context_start and offset[end_idx][1] >= end_char:\n",
        "                end_idx -= 1\n",
        "            found_end.append(end_idx + 1) # remove the last step\n",
        "\n",
        "        if len(found_start) > 0: # if found answer(s) in context span: add it/them to training data\n",
        "          for answer in range(len(found_start)):\n",
        "            input_ids.append(tokenized['input_ids'][i].unsqueeze(0))\n",
        "            attention_masks.append(tokenized['attention_mask'][i].unsqueeze(0))\n",
        "            token_type_ids.append(tokenized['token_type_ids'][i].unsqueeze(0))\n",
        "            start_pos.append(found_start[answer])\n",
        "            end_pos.append(found_end[answer])\n",
        "\n",
        "        else: # if no answer is (fully) in span of context: label is (0,0)\n",
        "          input_ids.append(tokenized['input_ids'][i].unsqueeze(0))\n",
        "          attention_masks.append(tokenized['attention_mask'][i].unsqueeze(0))\n",
        "          token_type_ids.append(tokenized['token_type_ids'][i].unsqueeze(0))\n",
        "          start_pos.append(0)\n",
        "          end_pos.append(0)\n",
        "\n",
        "\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  token_type_ids = torch.cat(token_type_ids, dim=0)\n",
        "  start_pos = torch.tensor(start_pos)\n",
        "  end_pos = torch.tensor(end_pos)\n",
        "\n",
        "  return input_ids, token_type_ids, attention_masks, start_pos, end_pos\n",
        "\n",
        "\n",
        "train_dataloader_reader = DataLoader(subjqa_train, batch_size = 32, shuffle = True, collate_fn = collate_batch_reader)\n",
        "val_dataloader_reader = DataLoader(subjqa_val, batch_size = 32, shuffle = True, collate_fn = collate_batch_reader)"
      ],
      "metadata": {
        "id": "3QAOTBUUx8R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter to be tuned (grid-search)\n",
        "stride_range = [50, 100, 150]\n",
        "lr_range = [1e-3, 1e-4]\n",
        "\n",
        "best_val_loss_overall = 4\n",
        "\n",
        "for stride_selected in stride_range:\n",
        "  for lr_selected in lr_range:\n",
        "    print(f'Selected stride = {stride_selected}    Selected Learning_rate = {lr_selected}\\n')\n",
        "\n",
        "    # load model and tokenizer\n",
        "    reader_model = AutoModelForQuestionAnswering.from_pretrained(\"deepset/minilm-uncased-squad2\", cache_dir = data_dir)\n",
        "    reader_tokenizer = AutoTokenizer.from_pretrained(\"deepset/minilm-uncased-squad2\", cache_dir = data_dir)\n",
        "\n",
        "    # since we cannot train all parameters (results in CUDA out of memory), we only fine-tune the final linear layer (and not the BERT corpus)\n",
        "    for param in reader_model.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    for param in reader_model.bert.encoder.layer[len(reader_model.bert.encoder.layer) - 1].output.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    for param in reader_model.bert.encoder.layer[len(reader_model.bert.encoder.layer) - 2].output.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    for param in reader_model.bert.encoder.layer[len(reader_model.bert.encoder.layer) - 3].output.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    for param in reader_model.qa_outputs.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "\n",
        "    reader_model = reader_model.to(device)\n",
        "    optimizer = torch.optim.Adam(reader_model.parameters(), lr = lr_selected)\n",
        "\n",
        "    num_epochs = 20\n",
        "    best_val_loss = 4\n",
        "\n",
        "    for epoch in range(num_epochs): \n",
        "      running_loss_train = []\n",
        "      reader_model.train()\n",
        "      for batch_train in tqdm(train_dataloader_reader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = reader_model(input_ids = batch_train[0].to(device),\n",
        "                              token_type_ids = batch_train[1].to(device),\n",
        "                              attention_mask = batch_train[2].to(device),\n",
        "                              start_positions = batch_train[3].to(device), \n",
        "                              end_positions = batch_train[4].to(device))\n",
        "        \n",
        "        outputs.loss.backward()\n",
        "        optimizer.step() # fine-tuning\n",
        "        running_loss_train.append(outputs.loss.item())\n",
        "\n",
        "      reader_model.eval()\n",
        "      running_loss_val = []\n",
        "      with torch.no_grad():\n",
        "        for batch_val in val_dataloader_reader:\n",
        "          outputs = reader_model(input_ids = batch_val[0].to(device),\n",
        "                                token_type_ids = batch_val[1].to(device),\n",
        "                                attention_mask = batch_val[2].to(device),\n",
        "                                start_positions = batch_val[3].to(device), \n",
        "                                end_positions = batch_val[4].to(device))\n",
        "          \n",
        "          running_loss_val.append(outputs.loss.item())\n",
        "\n",
        "      val_loss = np.mean(running_loss_val)\n",
        "\n",
        "      print(f'Epoch {epoch + 1}:\\nTraining Loss = {np.mean(running_loss_train)}   Validation Loss = {val_loss}\\n')\n",
        "\n",
        "      if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_reader_model_config = reader_model # best model over all epochs\n",
        "\n",
        "      else:\n",
        "        break\n",
        "\n",
        "    if best_val_loss < best_val_loss_overall:\n",
        "      best_val_loss_overall = best_val_loss\n",
        "      tuned_reader_model = best_reader_model_config # best model over all hyperparameters\n",
        "      print('Tuned reader model updated.')\n",
        "\n",
        "    print('------------------------------------\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovKlCLg1w3Gj",
        "outputId": "e44f856e-c824-4ea0-b74c-c364f87906a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected stride = 50    Selected Learning_rate = 0.001\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/41 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 41/41 [00:40<00:00,  1.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "Training Loss = 2.4393682828763636   Validation Loss = 2.1185587495565414\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [00:39<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2:\n",
            "Training Loss = 2.2706704604916457   Validation Loss = 2.091582641005516\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [00:40<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3:\n",
            "Training Loss = 2.1834744331313343   Validation Loss = 2.0783803164958954\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [00:40<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4:\n",
            "Training Loss = 2.1611015738510506   Validation Loss = 2.1552266776561737\n",
            "\n",
            "Tuned reader model updated.\n",
            "------------------------------------\n",
            "\n",
            "Selected stride = 50    Selected Learning_rate = 0.0001\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/41 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 41/41 [00:40<00:00,  1.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "Training Loss = 2.5436279453882356   Validation Loss = 2.1941229104995728\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [00:40<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2:\n",
            "Training Loss = 2.3575232174338363   Validation Loss = 2.1882901191711426\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [00:40<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3:\n",
            "Training Loss = 2.3193784632333894   Validation Loss = 2.1245640367269516\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [00:40<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4:\n",
            "Training Loss = 2.2677489315591206   Validation Loss = 2.111422821879387\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [00:40<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5:\n",
            "Training Loss = 2.2639458877284353   Validation Loss = 2.1683113425970078\n",
            "\n",
            "------------------------------------\n",
            "\n",
            "Selected stride = 100    Selected Learning_rate = 0.001\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/41 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 41/41 [00:41<00:00,  1.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "Training Loss = 2.4344759481709177   Validation Loss = 2.1162086725234985\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [00:40<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2:\n",
            "Training Loss = 2.287447408932011   Validation Loss = 2.072997957468033\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [00:41<00:00,  1.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3:\n",
            "Training Loss = 2.2045119913612923   Validation Loss = 2.051096647977829\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [00:41<00:00,  1.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4:\n",
            "Training Loss = 2.1353143918805007   Validation Loss = 2.1085850447416306\n",
            "\n",
            "Tuned reader model updated.\n",
            "------------------------------------\n",
            "\n",
            "Selected stride = 100    Selected Learning_rate = 0.0001\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/41 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 41/41 [00:41<00:00,  1.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "Training Loss = 2.552847635455248   Validation Loss = 2.194033235311508\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [00:40<00:00,  1.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2:\n",
            "Training Loss = 2.359352443276382   Validation Loss = 2.140195056796074\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [00:41<00:00,  1.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3:\n",
            "Training Loss = 2.311724217926584   Validation Loss = 2.0917259007692337\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [00:41<00:00,  1.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4:\n",
            "Training Loss = 2.2935649505475673   Validation Loss = 2.1084565222263336\n",
            "\n",
            "------------------------------------\n",
            "\n",
            "Selected stride = 150    Selected Learning_rate = 0.001\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/41 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 41/41 [00:42<00:00,  1.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "Training Loss = 2.435458974140446   Validation Loss = 2.0485027134418488\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [00:41<00:00,  1.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2:\n",
            "Training Loss = 2.3054281211480863   Validation Loss = 2.0561772286891937\n",
            "\n",
            "Tuned reader model updated.\n",
            "------------------------------------\n",
            "\n",
            "Selected stride = 150    Selected Learning_rate = 0.0001\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/41 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 41/41 [00:42<00:00,  1.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "Training Loss = 2.542048221681176   Validation Loss = 2.18615061044693\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [00:41<00:00,  1.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2:\n",
            "Training Loss = 2.347098591851025   Validation Loss = 2.134584456682205\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [00:41<00:00,  1.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3:\n",
            "Training Loss = 2.3102754325401493   Validation Loss = 2.0737644881010056\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [00:41<00:00,  1.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4:\n",
            "Training Loss = 2.2885160824147666   Validation Loss = 2.078025236725807\n",
            "\n",
            "------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_stride = 150 # save the tuned stride for subsequent usage in exercise 6)"
      ],
      "metadata": {
        "id": "1CML6BwqgfAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional Considerations"
      ],
      "metadata": {
        "id": "-bo6IJtCs1-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing a sample application of question answering (see below), it can be seen that the dataset itself also contains some noise. Arguably, the predicted answer fits better to the question than the true answer does."
      ],
      "metadata": {
        "id": "cx3rt_VKyx8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ex = subjqa_train[67]\n",
        "print('Question:', ex['question'])\n",
        "print('True Answer:', ex['answers']['text'])\n",
        "\n",
        "tokenized = reader_tokenizer(ex['question'], ex['context'], max_length = 512, stride = 100, return_tensors = \"pt\", pad_to_max_length = True)\n",
        "outputs = reader_model(**tokenized.to(device))\n",
        "start_ind = torch.argmax(outputs.start_logits)\n",
        "end_ind = torch.argmax(outputs.end_logits)\n",
        "print('Predicted:', reader_tokenizer.decode(tokenized['input_ids'][0][start_ind:end_ind +1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueVcOKF4FBgi",
        "outputId": "443c4a0e-7d67-4201-ff5a-55444b0b6cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Does this headphone look better?\n",
            "True Answer: ['mm headphone jack adapter']\n",
            "Predicted: these wireless headphones are really awesome\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 6"
      ],
      "metadata": {
        "id": "vSPqn4SeGxkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_string(s):\n",
        "  s = s.translate(str.maketrans('', '', string.punctuation))\n",
        "  s = \" \".join(s.split())\n",
        "  return s.lower()\n",
        "\n",
        "def F1_score(truth, pred):\n",
        "  if truth == '' and pred == '': # if both present empty strings, this results in a F1-score of one\n",
        "    return 1\n",
        "  else:\n",
        "    truth_s = truth.split()\n",
        "    pred_s = pred.split()\n",
        "    shared_words = len(set(truth_s) & set(pred_s)) # number of shared words\n",
        "    if shared_words > 0:\n",
        "      precision = shared_words / len(pred_s)\n",
        "      recall = shared_words / len(truth_s)\n",
        "      f1 = 2 * (precision * recall) / (precision + recall)\n",
        "      return f1\n",
        "    \n",
        "    else:\n",
        "      return 0"
      ],
      "metadata": {
        "id": "kf5jXdaXkpYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the non-finetuned reader model for comparison\n",
        "nonTuned_reader_model = AutoModelForQuestionAnswering.from_pretrained(\"deepset/minilm-uncased-squad2\", cache_dir = data_dir).to(device)"
      ],
      "metadata": {
        "id": "-GRCdqF6q_GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EM_tuned = 0\n",
        "EM_nonTuned = 0\n",
        "F1_tuned = []\n",
        "F1_nonTuned = []\n",
        "\n",
        "# instantiate question answering pipelines\n",
        "pipe_tuned = pipeline('question-answering', model = tuned_reader_model, tokenizer = reader_tokenizer, device = 0)\n",
        "pipe_nonTuned = pipeline('question-answering', model = nonTuned_reader_model, tokenizer = reader_tokenizer, device = 0)\n",
        "\n",
        "for sample in tqdm(subjqa_test):\n",
        "  query = sample['question']\n",
        "  answers = sample['answers']['text']\n",
        "\n",
        "  # use bi-encoder to retrieve top n contexts with highest cosine similaritity\n",
        "  query_emb = bi_encoder_model.encode(query)\n",
        "  cos_similarities = [cos_sim(query_emb, context['embedding']) for context in index_test]\n",
        "  rel_contexts = np.array(cos_similarities).argsort()[-n_best:][::-1] # optimized n from exercise 4)\n",
        "\n",
        "  # use fine-tuned cross-encoder to re-rank those n relevant contexts\n",
        "  scores = []\n",
        "  cross_encoder_model_t.eval()\n",
        "  with torch.no_grad():\n",
        "    for context_id in rel_contexts:\n",
        "      tokenized = cross_encoder_tokenizer(query, \n",
        "                                          index_test[context_id]['context'], \n",
        "                                          truncation = True,\n",
        "                                          max_length = 512, \n",
        "                                          return_tensors = \"pt\", \n",
        "                                          pad_to_max_length = True).to(device)\n",
        "      scores.append(cross_encoder_model_t(**tokenized).logits)\n",
        "\n",
        "  ranked_contexts = np.array(scores).argsort()[-k_best:][::-1] # optimized k from exercise 4)\n",
        "\n",
        "  # only keep the top k contexts after re-ranking\n",
        "  results = [{'context': index_test[rel_contexts[rank]]['context'], 'score': scores[rank]} for rank in ranked_contexts]\n",
        "\n",
        "  # retrieve the predictions of each of these contexts along with the associated scores\n",
        "  predictions_tuned_text = []\n",
        "  predictions_tuned_scores = []\n",
        "  predictions_nonTuned_text = []\n",
        "  predictions_nonTuned_scores = []\n",
        "  for rel_context in results:\n",
        "    # infer the span of the most likely answer using the fine-tuned reader model with the 'question-answering' pipeline\n",
        "    prediction_tuned = pipe_tuned(question = query, context = rel_context['context'], top_k = 1, doc_stride = tuned_stride, max_seq_len = 512, handle_impossible_answer = True)\n",
        "    predictions_tuned_text.append(prediction_tuned['answer'])\n",
        "    predictions_tuned_scores.append(prediction_tuned['score'])\n",
        "\n",
        "    prediction_nonTuned = pipe_nonTuned(question = query, context = rel_context['context'], top_k = 1, doc_stride = tuned_stride, max_seq_len = 512, handle_impossible_answer = True)\n",
        "    predictions_nonTuned_text.append(prediction_tuned['answer'])\n",
        "    predictions_nonTuned_scores.append(prediction_tuned['score'])\n",
        "\n",
        "  # among these k predictions, the one with the highest score (probabilitity) is selected and subsequently evaluated\n",
        "  answer_sel_tuned = predictions_tuned_text[np.argmax(np.array(predictions_tuned_scores))]\n",
        "  answer_sel_nonTuned = predictions_nonTuned_text[np.argmax(np.array(predictions_nonTuned_scores))]\n",
        "  \n",
        "  # instantiate metrics for this example\n",
        "  EM_tuned_found = False\n",
        "  EM_nonTuned_found = False\n",
        "  f1_tuned_scores = []\n",
        "  f1_nonTuned_scores = []\n",
        "\n",
        "  # normalise the predictions and label by removing punctuation, fixing whitespace, and converting to lowercase\n",
        "  result_tuned = normalize_string(answer_sel_tuned)\n",
        "  result_nonTuned = normalize_string(answer_sel_nonTuned)\n",
        "\n",
        "  # iterate through all exisiting true answers\n",
        "  range_answers = len(answers) if len(answers) > 0 else 1\n",
        "\n",
        "  for i in range(range_answers):\n",
        "    try:\n",
        "      answer = normalize_string(answers[i])\n",
        "    except IndexError: # if unanswerable question: the correct answer is ''\n",
        "      answer = ''\n",
        "\n",
        "\n",
        "    # Evaluate the performance of the whole pipeline on the EM and F1-score metrics\n",
        "    # EM\n",
        "    if result_tuned == answer or (result_tuned == '' and answer == ''):\n",
        "      EM_tuned_found = True\n",
        "\n",
        "    if result_nonTuned == answer or (result_nonTuned == '' and answer == ''):\n",
        "      EM_nonTuned_found = True\n",
        "\n",
        "    # F1\n",
        "    f1_tuned_scores.append(F1_score(answer, result_tuned))\n",
        "    f1_nonTuned_scores.append(F1_score(answer, result_nonTuned))\n",
        "\n",
        "\n",
        "  # if we have several answers, the EM score is equal to one if one of the answers has been exactly predicted\n",
        "  if EM_tuned_found:\n",
        "    EM_tuned += 1\n",
        "  if EM_nonTuned_found:\n",
        "    EM_nonTuned += 1\n",
        "\n",
        "  # if we have several answers, the highest F1 score among those answers is selected\n",
        "  F1_tuned.append(max(f1_tuned_scores))\n",
        "  F1_nonTuned.append(max(f1_nonTuned_scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd6-BmIqFbdz",
        "outputId": "0b7b9804-8ddc-40ad-ad46-99711b88b5c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/358 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py:978: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  UserWarning,\n",
            "100%|██████████| 358/358 [07:43<00:00,  1.30s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# comparison of results with non fine-tuned reader model\n",
        "print(f\"Average EM score of the finetuned reader model: {EM_tuned / len(subjqa_test)}\")\n",
        "print(f\"Average EM score of the non-finetuned reader model: {EM_nonTuned / len(subjqa_test)}\\n\")\n",
        "\n",
        "print(f\"Average F1 score of the finetuned reader model: {np.mean(F1_tuned)}\")\n",
        "print(f\"Average F1 score of the non-finetuned reader model: {np.mean(F1_nonTuned)}\\n\")\n",
        "\n",
        "# plot results\n",
        "x = np.arange(2) \n",
        "width = 0.2\n",
        "plt.figure(figsize=(15, 8))\n",
        "plt.bar(x-0.2, [EM_tuned / len(subjqa_test), np.mean(F1_tuned)], width, color='blue') \n",
        "plt.bar(x+0.2, [EM_nonTuned / len(subjqa_test), np.mean(F1_nonTuned)], width, color='red') \n",
        "plt.xticks(x, ['Exact Match (EM)', 'F1-Score']) \n",
        "plt.xlabel(\"Metric\") \n",
        "plt.ylabel(\"Performance\") \n",
        "plt.legend([\"Fine-tuned reader model\", \"Non fine-tuned reader model\"]) \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "dIaRoiGWhVlq",
        "outputId": "aff26e1c-8eae-4a10-e5ad-23cf909d8806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average EM score of the finetuned reader model: 0.28212290502793297\n",
            "Average EM score of the non-finetuned reader model: 0.28212290502793297\n",
            "\n",
            "Average F1 score of the finetuned reader model: 0.3704628035223366\n",
            "Average F1 score of the non-finetuned reader model: 0.3704628035223366\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the final results, it can be seen that quite a good performance given the difficulty of the problem and (noisy) dataset at hand was achieved.\n",
        "\n",
        "Interestingly, the results between the fine-tuned and non fine-tuned reader model do not differ at all. This might be the case because the respective predictions (spans) were pretty clear and/or the reader model itself is very stable such that fine-tuning over a few epochs does not alter its predictions.\n",
        "Also, the initial reader model is already fine-tuned on SQuAD 2.0, which might be another contributing factor."
      ],
      "metadata": {
        "id": "UAit9byPFp4-"
      }
    }
  ]
}